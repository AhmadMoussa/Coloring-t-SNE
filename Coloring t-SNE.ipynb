{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coloring t-SNE\n",
    "\n",
    "[t-SNE](https://lvdmaaten.github.io/tsne/) is great at capturing a combination of the local and global structure of a dataset in 2d or 3d. But when plotting points in 2d, there are often interesting patterns in the data that only come out as \"texture\" in the point cloud. When the plot is colored appropriately, these patterns can be made more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import IncrementalPCA, FastICA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load some data: a 128 dimensional embedding output from a VAE, and a 2 dimensional representation of those vectors based on running t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data128 = np.load('data128.npy')\n",
    "print data128.shape\n",
    "%time data2 = np.load('data2.npy')\n",
    "print data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "\n",
    "When we visualize the raw data itself the \"texture\" is clear, but not as clear as the different \"islands\" and clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(xy, colors=None, alpha=0.25, figsize=(6,6), s=0.5, cmap='hsv'):\n",
    "    plt.figure(figsize=figsize, facecolor='white')\n",
    "    plt.margins(0)\n",
    "    plt.axis('off')\n",
    "    fig = plt.scatter(xy[:,0], xy[:,1],\n",
    "                c=colors, # set colors of markers\n",
    "                cmap=cmap, # set color map of markers\n",
    "                alpha=alpha, # set alpha of markers\n",
    "                marker=',', # use smallest available marker (square)\n",
    "                s=s, # set marker size. single pixel is 0.5 on retina, 1.0 otherwise\n",
    "                lw=0, # don't use edges\n",
    "                edgecolor='') # don't use edges\n",
    "    # remove all axes and whitespace / borders\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "plot_tsne(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of pulling out a real feature from the data is to look at the nearest neighbors in 2d and see how far away they are on average in the original high dimensional space. This suggestion comes from [Martin Wattenberg](https://twitter.com/wattenberg). First we compute the indices for all the nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nns = NearestNeighbors(n_neighbors=10).fit(data2)\n",
    "%time distances, indices = nns.kneighbors(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we compute the distances in high dimensional space, and normalize them between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances = []\n",
    "for point, neighbor_indices in zip(data128, indices):\n",
    "    neighbor_points = data128[neighbor_indices[1:]] # skip the first one, which should be itself\n",
    "    cur_distances = np.sum([euclidean(point, neighbor) for neighbor in neighbor_points])\n",
    "    distances.append(cur_distances)\n",
    "distances = np.asarray(distances)\n",
    "distances -= distances.min()\n",
    "distances /= distances.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the distances look sort of gaussian with a long tail. We clip the ends to draw out the details in the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.clip(distances, 0.2, 0.4), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(data2, np.clip(distances, 0.2, 0.4), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D t-SNE\n",
    "\n",
    "One technique is to compute t-SNE in 3D and use the results as colors. This can take a long time to compute with large datasets. This is the technique that was used for the [Infinite Drum Machine](https://aiexperiments.withgoogle.com/drum-machine).\n",
    "\n",
    "```python\n",
    "from bhtsne import tsne\n",
    "data3 = tsne(data128, dimensions=3)\n",
    "data3 -= np.min(data3, axis=0)\n",
    "data3 /= np.max(data3, axis=0)\n",
    "plot_tsne(data2, data3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D/24D PCA\n",
    "\n",
    "Another approach is to use PCA, which is must faster but does not show as much structure in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=3)\n",
    "%time pca_projection = pca.fit_transform(data128)\n",
    "pca_projection -= np.min(pca_projection, axis=0)\n",
    "pca_projection /= np.max(pca_projection, axis=0)\n",
    "plot_tsne(data2, pca_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using PCA to 3D, we can also do PCA to 24 dimensions, comparing the dimensions to the median of each, and using those comparisons as bits in a 24-bit color. This suggestion comes from [Mario Klingemann](https://twitter.com/quasimondo) This technique can work well with only 12 dimensions (4 bits per color). It doesn't make sense in a \"continuous\" space (normalizing and multiplying the shuffled bits by the basis directly, rather than testing against the median first). That just makes the colors all muddled, more similar to the 3D PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def projection_to_colors(projection, bits_per_channel=8):\n",
    "    basis = 2**np.arange(bits_per_channel)[::-1]\n",
    "    basis = np.hstack([basis, basis, basis])\n",
    "    shuffled = np.hstack([projection[:,0::3], projection[:,1::3], projection[:,2::3]])\n",
    "    bits = (shuffled > np.median(shuffled, axis=0)) * basis\n",
    "    # if we stacked into a 3d tensor we could do this a little more efficiently\n",
    "    colors = np.vstack([bits[:,:(bits_per_channel)].sum(axis=1),\n",
    "                        bits[:,(bits_per_channel):(2*bits_per_channel)].sum(axis=1),\n",
    "                        bits[:,(2*bits_per_channel):(3*bits_per_channel)].sum(axis=1)]).astype(float).T\n",
    "    return colors / (2**bits_per_channel - 1)\n",
    "    \n",
    "def pack_binary_pca(data, bits_per_channel=8):\n",
    "    bits_per_color = 3 * bits_per_channel\n",
    "    pca = IncrementalPCA(n_components=bits_per_color)\n",
    "    pca_projection = pca.fit_transform(data)\n",
    "    return projection_to_colors(pca_projection, bits_per_channel)\n",
    "\n",
    "%time colors = pack_binary_pca(data128, 8)\n",
    "plot_tsne(data2, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D/24D ICA\n",
    "\n",
    "Another approach is to use ICA, which can be a little slower than PCA, but shows different features depending on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=3)\n",
    "%time ica_projection = ica.fit_transform(data128)\n",
    "ica_projection -= np.min(ica_projection, axis=0)\n",
    "ica_projection /= np.max(ica_projection, axis=0)\n",
    "plot_tsne(data2, ica_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do ICA to 24 dimensions and pack it into colors. This might make less sense than PCA theoretically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_binary_ica(data, bits_per_channel=8):\n",
    "    bits_per_color = 3 * bits_per_channel\n",
    "    ica = FastICA(n_components=bits_per_color, max_iter=500)\n",
    "    ica_projection = ica.fit_transform(data)\n",
    "    return projection_to_colors(ica_projection, bits_per_channel)\n",
    "\n",
    "%time colors = pack_binary_ica(data128, 8)\n",
    "plot_tsne(data2, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "Another approach that shows up in the [LargeVis Paper](https://arxiv.org/abs/1602.00370) is to compute K-Means on the high dimensional data and then use those labels as color indices. We can try with 8, 30, and 128 cluster K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=8)\n",
    "%time labels = kmeans.fit_predict(data128)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=30)\n",
    "%time labels = kmeans.fit_predict(data128)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=128)\n",
    "%time labels = kmeans.fit_predict(data128)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the \"boundaries\" between colors seem fairly arbitrary, but K-Means has a nice property of allowing us to identify the centers of these color regions if we want to provide exemplars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "%time neighbors.fit(data128)\n",
    "%time distances, indices = neighbors.kneighbors(kmeans.cluster_centers_)\n",
    "\n",
    "plt.figure(figsize=(6,6), facecolor='white')\n",
    "plt.margins(0)\n",
    "plt.axis('off')\n",
    "fig = plt.scatter(data2[:,0], data2[:,1], alpha=0.5, marker=',', s=0.5, lw=0, edgecolor='', c=labels, cmap='hsv')\n",
    "plt.scatter(data2[indices,0], data2[indices,1], marker='.', s=250, c=(0,0,0))\n",
    "plt.scatter(data2[indices,0], data2[indices,1], marker='.', s=100, c=labels[indices], cmap='hsv')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neighbors can be slow, but the mrpt library is much faster.\n",
    "\n",
    "```python\n",
    "import mrpt\n",
    "data128f32 = data128.astype(np.float32)\n",
    "%time nn = mrpt.MRPTIndex(data128f32, depth=5, n_trees=100)\n",
    "%time nn.build()\n",
    "def kneighbors(nn, queries, k, votes_required=4):\n",
    "    return np.asarray([nn.ann(query, k, votes_required=votes_required) for query in queries])\n",
    "%time indices = kneighbors(nn, data128f32[:100], 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argmax\n",
    "\n",
    "Another technique, arguably the most evocative, is to use the argmax of each high dimensional vector. The motivation for using argmax is that high dimensional data is so sparse that \"nearby\" points should have a similar ordering of their dimensions: if you sorted the dimensions of two nearby points, the difference should be small. This means that their argmax (the largest dimensions) should probably be shared. If we do this without any modification to the high dimensional data, we get a fairly homogenous plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(data2, np.argmax(data128, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because a few dimensions dominate the argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(data128, axis=1), bins=128)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we standardize each dimension then there is a more even distribution of possible argmax values, and therefore more even distribution of colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    std = np.copy(data)\n",
    "    std -= std.mean(axis=0)\n",
    "    std /= std.std(axis=0)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data128_standardized = standardize(data128)\n",
    "plt.hist(np.argmax(data128_standardized, axis=1), bins=128)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(data2, np.argmax(data128_standardized, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the high dimensional data has both negative and positive components, so it might make more sense to take the absolute value before computing the argmax. In this case, it makes things visually \"messier\" with too many overlapping colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(data2, np.argmax(np.abs(data128_standardized), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + argmax\n",
    "\n",
    "Because some of the dimensions are correlated with each other in this case, it might make sense to do PCA before taking the argmax. Again if we take the argmax without standardizing the high dimensional data, a few colors dominate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=30)\n",
    "%time pca_projection = pca.fit_transform(data128)\n",
    "labels = np.argmax(pca_projection, axis=1)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the distribution of argmax results are concentrated toward the first dimensions of the PCA projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(pca_projection, axis=1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we standardize it we see a more even distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_standardized = standardize(pca_projection)\n",
    "plt.hist(np.argmax(projection_standardized, axis=1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can take the standardized argmax, and the argmax of the absolute values of the standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(data2, np.argmax(projection_standardized, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(data2, np.argmax(np.abs(projection_standardized), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer the non-absolute value argmax in this case. Now we can run the whole process again for different number of output components from PCA. Here it is for 16 and 128 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=16)\n",
    "%time pca_projection = pca.fit_transform(data128)\n",
    "labels = np.argmax(standardize(pca_projection), axis=1)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=128)\n",
    "%time pca_projection = pca.fit_transform(data128)\n",
    "labels = np.argmax(standardize(pca_projection), axis=1)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be possible to \"tune\" the amount of color variation by an element-wise multiplication between each PCA projected vector and a vector with some \"falloff\" that gives more weight to the earlier dimensions and less weight to the final dimensions.\n",
    "\n",
    "## ICA + argmax\n",
    "\n",
    "We can try the same technique, but using ICA instead of PCA. Here for 8, 30, and 128 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=8, max_iter=500)\n",
    "%time ica_projection = ica.fit_transform(data128)\n",
    "labels = np.argmax(standardize(ica_projection), axis=1)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=30, max_iter=500)\n",
    "%time ica_projection = ica.fit_transform(data128)\n",
    "labels = np.argmax(standardize(ica_projection), axis=1)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=128, max_iter=500)\n",
    "%time ica_projection = ica.fit_transform(data128)\n",
    "labels = np.argmax(standardize(ica_projection), axis=1)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA/PCA + K-Means\n",
    "\n",
    "Finally, we can try computing K-Means on top of the dimensionality reduced vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=128)\n",
    "%time labels = kmeans.fit_predict(pca_projection)\n",
    "plot_tsne(data2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=128)\n",
    "%time labels = kmeans.fit_predict(ica_projection)\n",
    "plot_tsne(data2, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
